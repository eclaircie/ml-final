{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4f09300",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'toLowercase'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 62\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m#def main():\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m#nb = MultinomialNB(force_alpha=True)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m#nb.fit(X, y)\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m training_set \u001b[38;5;241m=\u001b[39m process_text(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(training_set)\n\u001b[0;32m     64\u001b[0m dictionary \u001b[38;5;241m=\u001b[39m create_dict(training_set, \u001b[38;5;241m150\u001b[39m)\n",
      "Cell \u001b[1;32mIn [21], line 46\u001b[0m, in \u001b[0;36mprocess_text\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#print (strings)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m#print(labels)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#strings_norm = []\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m strings :\n\u001b[1;32m---> 46\u001b[0m     \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcolumn_stack(strings,label)\n",
      "Cell \u001b[1;32mIn [21], line 8\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(example)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(example):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# make everything lowercase \u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoLowercase\u001b[49m()\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# strip html tags, replace with \"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     example \u001b[38;5;241m=\u001b[39m example\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m1,2}\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'toLowercase'"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def normalize(example):\n",
    "    # make everything lowercase \n",
    "    example = example.toLowercase()\n",
    "    \n",
    "    # strip html tags, replace with \"\"\n",
    "    example = example.replace('\\<\\w{1,2}\\>', '')\n",
    "    \n",
    "    # remove punctuation; \n",
    "    #replace with keyword \" _PUNCT \" (including spaces)\n",
    "    example = example.replace('\\W', ' _PUNCT ')\n",
    "    \n",
    "    # remove links, replace with keyword \" _EXTERNALLINK \"\n",
    "    example = example.replace('(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w\\.-]*)', ' _EXTERNALLINK ')\n",
    "\n",
    "    # replace all excessive whitespace with a single space; \n",
    "    #(this will also normalize the punctuation & link counters above)\n",
    "    example = example.replace('\\s{2,}', ' ')\n",
    "\n",
    "    #return void\n",
    "\n",
    "\n",
    "def process_text(filename):\n",
    "    # read 4th col of file (data) + 5th col (label)\n",
    "    strings =[]\n",
    "    labels = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    with open (filename,'r', encoding=\"utf-8\") as csvfile:\n",
    "        csvdata = csv.reader(csvfile)\n",
    "        \n",
    "        for row in csvdata:\n",
    "            strings.append(row[3])\n",
    "            #labels.append(int(row[4]))\n",
    "            labels.append(row[4])\n",
    "    \n",
    "    #print (strings)\n",
    "    #print(labels)\n",
    "    #strings_norm = []\n",
    "    for example in strings :\n",
    "        normalize(example)\n",
    "    \n",
    "    return np.column_stack(strings,label)\n",
    "    \n",
    "\n",
    "    \n",
    "#create dictionary of most common words from an array of strings, where spam = 1\n",
    "#default dict size is 500 words\n",
    "def create_dict(arr, size=500):\n",
    "    return\n",
    "    \n",
    "    \n",
    "#def main():\n",
    "    #nb = MultinomialNB(force_alpha=True)\n",
    "    #nb.fit(X, y)\n",
    "    \n",
    "training_set = process_text('Training.csv')\n",
    "print(training_set)\n",
    "dictionary = create_dict(training_set, 150) #150 words\n",
    "\n",
    "#make feature vectors for each comment, store in list, dictsize x no. of features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b4c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
